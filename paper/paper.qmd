---
title: "Beyoncé"
author: Tam Ly
thanks: "Code and data are available at: [https://github.com/atn-ly/beyonce](https://github.com/atn-ly/beyonce)"
date: today
date-format: long
abstract: "First sentence. Second sentence. Third sentence. Fourth sentence."
format: pdf
number-sections: true
bibliography: references.bib
toc: true
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(rstanarm)
library(knitr)
library(here)
library(ggplot2)
library(arrow)
library(scales)
library(modelsummary)
library(marginaleffects)

#Read in data
beyonce_cleaned = read_parquet(
  file = here("data/analysis_data/beyonce_cleaned.parquet"),
  show_col_types = FALSE
)

#Read in model
beyonce_pois <- readRDS(file = here::here("models/beyonce_pois.rds"))
beyonce_nbinom <- readRDS(file = here::here("models/beyonce_nbinom.rds"))
beyonce_nbinom_default <- readRDS(file = here::here("models/beyonce_nbinom_default.rds"))
```


# Introduction



# Data {#sec-data}

## Source and Methodology

The dataset used in this paper was created using data gathered from Spotify [@spotify] and Billboard [@billboard]. The data was collected for the purpose of this paper to investigate the number of Spotify streams based on weeks spent on the *Billboard Hot 100* for Beyoncé songs. Song titles, album titles, and the number of Spotify streams were collected from Spotify [@spotify], while weeks spent on the *Billboard Hot 100* were collected from Billboard [@billboard]. There were no similar datasets available that could have been used.

We analyzed the data in R [@citeR] using the following packages: `arrow` [@arrow], `ggplot2` [@ggplot2], `here` [@here], `janitor` [@janitor], `kable` [@kable], `knitr` [@knitr], `marginaleffects` [@marginaleffects], `modelsummary` [@modelsummary], `rstanarm` [@rstanarm], `scales` [@scales], and `tidyverse` [@tidyverse].

## Variables

There are 4 variables in this dataset:

1. `song` which represents the song titles,
2. `album` which represents the album titles,
3. `spotify_streams` which represents the number of Spotify streams, and
4. `wks_on_chart` which represents the number of weeks spent on the *Billboard Hot 100*.

@tbl-variables shows a sample of the dataset with all the variables and the first 10 out of 140 observations.

```{r}
#| echo: false
#| label: tbl-variables
#| tbl-cap: "Sample of the cleaned dataset with the first 10 observations"

beyonce_cleaned |>
  slice(1:10) |>
  kable(
    col.names = c("Song", "Album", "Spotify Streams", "Weeks on Chart")
  )
```

@fig-variables summarizes the data with all 140 observations. We see a positive correlation between the number of Spotify streams and weeks spent on the *Billboard Hot 100*.

```{r}
#| echo: false
#| label: fig-variables
#| fig-cap: "Relationship between the number of Spotify streams and weeks spent on the *Billboard Hot 100* for Beyoncé songs"

beyonce_cleaned |>
  ggplot(mapping = aes(x = wks_on_chart, y = spotify_streams, color = fct_inorder(album))) +
  geom_point() +
  theme_minimal() +
  labs(x = "Weeks on Chart", y = "Spotify Streams", color = "Album")
```

## Measurement

First, we used Spotify [@spotify] to collect data on Beyoncé albums. Here, we had to decide which albums to include in our dataset since Beyoncé has 15 different albums in her Spotify discography. We decided to only include her eight studio albums and one soundtrack album and exclude her live albums and compilation albums because these are not as popular. Furthermore, among her eight studio albums, we only looked at the deluxe versions, since these contain the same songs with the same streaming numbers as the standard version along with some additional tracks.

Next, using Spotify [@spotify], we collected data on Beyoncé songs from the nine albums we selected and had to decide which types of tracks to include. Since we are interested in songs that charted, we decided to exclude remixes, extended mixes, Spanish versions, interludes, and original demos that were included in her albums because these are not as popular. Note that we also did not include songs where Beyoncé was a guest feature on another artist’s song.

Then, we used Spotify [@spotify] to collect data on the number of streams for the songs that we selected. Spotify gives one stream to a track if it is played for at least 30 seconds and updates its streaming numbers once a day at approximately 3 PM EST [@spotify]. We collected this data on April 12, 2024 after 3 PM EST.

Lastly, we collected data on the number of weeks each song spent on the *Billboard Hot 100* from Billboard [@billboard]. Billboard keeps a chart history for Beyoncé that includes the debut date, peak position, peak date, and weeks spent for each song that charted on the *Billboard Hot 100*. From this list, we only collected the number of weeks spent on the chart for our selected songs. Billboard updates the *Billboard Hot 100* as well as the artist’s chart history every Tuesday [@billboard]. We collected this data on Friday, April 12, 2024. For songs that did not chart, we recorded them with a 0 in our dataset.


# Model {#sec-model}

The goal of our modeling strategy is to predict the number of Spotify streams for a Beyoncé song based on the number of weeks it spent on the *Billboard Hot 100*. We used a negative binomial regression model in a Bayesian framework. Negative binomial regression is a type of generalized linear model that is useful for modeling count data.

## Model set-up

The model that we are interested in is:

\begin{align} 
y_i|\mu_i,r &\sim \mbox{NegBinom}(\mu_i, r) \\
\mbox{log}(\mu_i) &= \alpha + \beta \times \mbox{Number of weeks}_i \\
\alpha &\sim \mbox{Normal}(18, 2.5) \\
\beta &\sim \mbox{Normal}(0, 2.5) \\
\end{align}

Where:

* $y_i$ is the outcome variable, representing the number of Spotify streams for song $i$,
* $\mu_i$ is a parameter for the negative binomial distribution, representing the probability of success in a single trial,
* $r$ is a parameter for the negative binomial distribution, representing the number of successes,
* $\mbox{Number of weeks}_i$ is the predictor variable, representing the number of weeks spent on the Billboard Hot 100 for song $i$,
* $\alpha$ is a parameter, representing the intercept with a specified prior probability distribution that is Normal with a mean of 18 and standard deviation of 2.5, and 
* $\beta$ is a parameter, representing the slope coefficient with a default prior probability distribution that is Normal with a mean of 0 and standard deviation of 2.5.

## Model justification

We expect a positive relationship between the number of Spotify streams and weeks spent on the *Billboard Hot 100* based on the positive correlation in the graph that we observed in @sec-data. 

Negative binomial regression operates under several assumptions. It assumes linearity between the outcome and predictor variables, independence of observations, and no multicollinearity. 

We considered Poisson regression as an alternative model since it is also used for count data. However, one of the restrictions with Poisson regression is that it assumes equal mean and variance. Negative binomial regression relaxes this assumption to allow for over-dispersion. We fitted both and compared them using posterior predictive checks in @fig-modelcomparison. We see that the negative binomial approach does a better job of fitting the data.

We implemented additional model checking and diagnostic issues. Details and graphs can be found in @sec-model-details.

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-modelcomparison
#| layout-ncol: 2
#| fig-cap: "Comparing posterior prediction checks for Poisson and negative binomial models"
#| fig-subcap: ["Poisson model", "Negative binomial model"]

pp_check(beyonce_pois) +
  theme(legend.position = "bottom")

pp_check(beyonce_nbinom) +
  theme(legend.position = "bottom")
```

# Results {#sec-results}



# Discussion {#sec-discussion}

## First discussion point

## Second discussion point

## Third discussion point

## Weaknesses and next steps



\newpage

\appendix

# Appendix {-}

# Model details {#sec-model-details}

## Posterior predictive check

We compare the posterior with the prior. @fig-posteriorvsprior-1 suggests that there is an issue with the default prior we specified for $\alpha$. Our re-specified model in @fig-posteriorvsprior-2 shows that it does a better job of fitting the data.

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-posteriorvsprior
#| fig-cap: "Comparing the posterior with the prior"
#| fig-subcap: ["Default priors", "Re-specified priors"]
#| layout-ncol: 2

posterior_vs_prior(beyonce_nbinom_default) +
  theme_minimal() +
  scale_color_brewer(palette = "Set1") +
  theme(legend.position = "bottom") +
  coord_flip()

posterior_vs_prior(beyonce_nbinom) +
  theme_minimal() +
  scale_color_brewer(palette = "Set1") +
  theme(legend.position = "bottom") +
  coord_flip()
```

## Diagnostics

@fig-diagnostics-1 is a trace plot and it shows that there are no horizontal lines that appear to bounce around and have a nice overlap between the chains. @fig-diagnostics-2 is a Rhat plot and it shows that everything is close to 1 and no more than 1.1. This suggests that there are no problems in both.

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-diagnostics
#| fig-cap: "Checking the convergence of the MCMC algorithm"
#| fig-subcap: ["Trace plot", "Rhat plot"]
#| layout-ncol: 2

plot(beyonce_nbinom, "trace")

plot(beyonce_nbinom, "rhat")
```


\newpage

# References
