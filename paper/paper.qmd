---
title: "Beyoncé"
author: Tam Ly
thanks: "Code and data are available at: [https://github.com/atn-ly/beyonce](https://github.com/atn-ly/beyonce)"
date: today
date-format: long
abstract: "First sentence. Second sentence. Third sentence. Fourth sentence."
format: pdf
number-sections: true
bibliography: references.bib
toc: true
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(rstanarm)
library(knitr)
library(here)
library(ggplot2)
library(arrow)
library(scales)
library(modelsummary)
library(marginaleffects)

#Read in data
beyonce_cleaned = read_parquet(
  file = here("data/analysis_data/beyonce_cleaned.parquet"),
  show_col_types = FALSE
)

#Read in model
beyonce_pois <- readRDS(file = here::here("models/beyonce_pois.rds"))
beyonce_nbinom <- readRDS(file = here::here("models/beyonce_nbinom.rds"))
beyonce_nbinom_default <- readRDS(file = here::here("models/beyonce_nbinom_default.rds"))
```


# Introduction



# Data {#sec-data}

## Source and Methodology

The dataset used in this paper was created using data gathered from Spotify [@spotify] and Billboard [@Billboard]. The data was collected for the purpose of this paper to investigate the number of Spotify streams based on weeks spent on the *Billboard Hot 100* for Beyoncé songs. Song titles, album titles, and the number of Spotify streams were collected from Spotify [@spotify], while weeks spent on the *Billboard Hot 100* were collected from Billboard [@Billboard]. There were no similar datasets available that could have been used.

We analyzed the data in R [@citeR] using the following packages: `arrow` [@arrow], `ggplot2` [@ggplot2], `here` [@here], `janitor` [@janitor], `kable` [@kable], `knitr` [@knitr], `marginaleffects` [@marginaleffects], `modelsummary` [@modelsummary], `rstanarm` [@rstanarm], `scales` [@scales], and `tidyverse` [@tidyverse].

## Variables

There are 4 variables in this dataset:

1. `song` which represents the song titles,
2. `album` which represents the album titles,
3. `spotify_streams` which represents the number of Spotify streams, and
4. `wks_on_chart` which represents the number of weeks spent on the *Billboard Hot 100*.

@tbl-variables shows a sample of the dataset with all the variables and the first 10 out of 140 observations.

```{r}
#| echo: false
#| label: tbl-variables
#| tbl-cap: "Sample of the cleaned dataset with the first 10 observations"

beyonce_cleaned |>
  slice(1:10) |>
  kable(
    col.names = c("Song", "Album", "Spotify Streams", "Weeks on Chart")
  )
```

@fig-variables summarizes the data with all 140 observations. We see a positive correlation between the number of Spotify streams and weeks spent on the *Billboard Hot 100*.

```{r}
#| echo: false
#| label: fig-variables
#| fig-cap: "Relationship between the number of Spotify streams and weeks spent on the *Billboard Hot 100* for Beyoncé songs"

beyonce_cleaned |>
  ggplot(mapping = aes(x = wks_on_chart, y = spotify_streams, color = fct_inorder(album))) +
  geom_point() +
  theme_minimal() +
  labs(x = "Weeks on Chart", y = "Spotify Streams", color = "Album")
```

## Measurement



# Model {#sec-model}

The goal of our modeling strategy is to predict the number of Spotify streams for a Beyoncé song based on the number of weeks it spent on the *Billboard Hot 100*. We used a negative binomial regression model in a Bayesian framework. Negative binomial regression is a type of generalized linear model that is useful for modeling count data.

## Model set-up

The model that we are interested in is:

\begin{align} 
y_i|\mu_i,r &\sim \mbox{NegBinom}(\mu_i, r) \\
\mbox{log}(\mu_i) &= \alpha + \beta \times \mbox{Number of weeks}_i \\
\alpha &\sim \mbox{Normal}(0, 2.5) \\
\beta &\sim \mbox{Normal}(0, 2.5) \\
\end{align}

Where:

* $y_i$ is the outcome variable, representing the number of Spotify streams for song $i$,
* $\mu_i$ is a parameter for the negative binomial distribution, representing the probability of success in a single trial,
* $r$ is a parameter for the negative binomial distribution, representing the number of successes,
* $\mbox{Number of weeks}_i$ is the predictor variable, representing the number of weeks spent on the Billboard Hot 100 for song $i$,
* $\alpha$ is a parameter, representing the intercept with a specified prior probability distribution that is Normal with a mean of 18 and standard deviation of 2.5, and 
* $\beta$ is a parameter, representing the slope coefficient with a default prior probability distribution that is Normal with a mean of 0 and standard deviation of 2.5.

## Model justification

We expect a positive relationship between the number of Spotify streams and weeks spent on the *Billboard Hot 100* based on the positive correlation in the graph that we observed in @sec-data. 

Negative binomial regression operates under several assumptions. It assumes linearity between the outcome and predictor variables, independence of observations, and no multicollinearity. 

We considered Poisson regression as an alternative model since it is also used for count data. However, one of the restrictions with Poisson regression is that it assumes equal mean and variance. Negative binomial regression relaxes this assumption to allow for over-dispersion. We fitted both and compared them using posterior predictive checks in @fig-modelcomparison. We see that the negative binomial approach does a better job of fitting the data.

We implemented additional model checking and diagnostic issues. Details and graphs can be found in @sec-model-details.

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-modelcomparison
#| layout-ncol: 2
#| fig-cap: "Comparing posterior prediction checks for Poisson and negative binomial models"
#| fig-subcap: ["Poisson model", "Negative binomial model"]

pp_check(beyonce_pois) +
  theme(legend.position = "bottom")

pp_check(beyonce_nbinom) +
  theme(legend.position = "bottom")
```

# Results {#sec-results}



# Discussion {#sec-discussion}

## First discussion point

## Second discussion point

## Third discussion point

## Weaknesses and next steps



\newpage

\appendix

# Appendix {-}

# Model details {#sec-model-details}

## Posterior predictive check

We compare the posterior with the prior. @fig-posteriorvsprior-1 suggests that there is an issue with the default prior we specified for $\alpha$. Our re-specified model in @fig-posteriorvsprior-2 shows that it does a better job of fitting the data.

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-posteriorvsprior
#| fig-cap: "Comparing the posterior with the prior"
#| fig-subcap: ["Default priors", "Re-specified priors"]
#| layout-ncol: 2

posterior_vs_prior(beyonce_nbinom_default) +
  theme_minimal() +
  scale_color_brewer(palette = "Set1") +
  theme(legend.position = "bottom") +
  coord_flip()

posterior_vs_prior(beyonce_nbinom) +
  theme_minimal() +
  scale_color_brewer(palette = "Set1") +
  theme(legend.position = "bottom") +
  coord_flip()
```

## Diagnostics

@fig-diagnostics-1 is a trace plot and it shows that there are no horizontal lines that appear to bounce around and have a nice overlap between the chains. @fig-diagnostics-2 is a Rhat plot and it shows that everything is close to 1 and no more than 1.1. This suggests that there are no problems in both.

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-diagnostics
#| fig-cap: "Checking the convergence of the MCMC algorithm"
#| fig-subcap: ["Trace plot", "Rhat plot"]
#| layout-ncol: 2

plot(beyonce_nbinom, "trace")

plot(beyonce_nbinom, "rhat")
```


\newpage

# References
